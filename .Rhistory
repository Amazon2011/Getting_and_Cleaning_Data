colIndex
govNGAP <- read.xlsx("gov_NGAP.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
govNGAP
rename(govNGAP, dat)
dat <- govNGAP
sum(dat$Zip*dat$Ext,na.rm=T)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
library(XML)
doc <- xmlTreeParse(url, useInternal = TRUE)
doc <- xmlTreeParse(url)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url, "2006_microdata_survey_Idaho_state.csv")
?fread
DT <- read.csv("2006_microdata_survey_Idaho_state.csv", header = TRUE)
head(DT)
library(RMySQL)
hg19 <- dbConnect(MySQL(), user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
appyData <- dbReadTable(hg19, "affyU133Plus2")
head(appyData)
source("http://bioconductor.org/biocLite.R")
biocLite(rhdf5)
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created
h5ls("example.h5")
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix(1:10, nr=5, nc=2)
h5write(A, "example.h5", "foo/A")
B = array(seq(0.1, 2.0, by=0.1), dim=c(5,2,2))
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
h5read("example.h5", "foo/A")
con= url("http://scholar.google.com/citations?user=HI-I6C0AAAA&hl=en")
htmlcode = readLines(con
)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
getwd()
dir
dir.create("Data")
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
fileUrl
download.file(fileUrl, destfile="./data/cameras.csv", method="curl")
library(XML)
fileUrl <- "http:/www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl, useInteral = TRUE)
doc <- xmlTreeParse(fileUrl, useInternal = TRUE)
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl, useInternal=T)
doc
scores <- xpathSApplay(doc,"//li[@class='score']",xmlValue)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
scores
teams <- xpathSApplay(doc,"//li[@class='team-name']", xmlvALUE)
teams <- xpathSApplay(doc,"//li[@class='team-name']", xmlValue)
teams <- xpathSApply(doc,"//li[@class='team-name']", xmlValue)
doc
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
names(jsonData$owner)
names(jsonData$id)
jsonData$owner
jsonData$owner$login
myjson<- toJSON(iris, pretty=T)
cat(myjson)
iris2 <- fromJSON(myjson)
head(iris2)
library(data.table)
DF = data.frame(x = rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
head(DF,3)
DT = data.table(x = rnorm(9), y=rep(c("a","b","c"), each=3), z=rnorm(9))
head(DT,3)
tables()
DT[2, ]
DT[DT$y=="a",]
DT[c(2, 3)]
DT[,list(mean(x), sum(z))]
DT[,mean(x)]
DT[,table(y)]
DT[,w:=z^2]
DT
DT[,m:={tmp<- (x+z); log2(tmp+5)}]
DT
set.seed(123)
DT <- data.table(x=sample(letters[1:3], 1E5, TRUE))
DT
nrows(DT)
DT[,.N]
DT[,.N, by=x]
DT <- data.table(x=rep(c("a", "b", "c"), each=100), y=rnorm(300))
head(DT)
setkey(DT, X)
setkey(DT, x)
DT['a']
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/2006_microdata_survey_about_housing_Idaho.csv")
x <- read.csv("./data/2006_microdata_survey_about_housing_Idaho.csv", header = TRUE)
head(x)
x[, x$VAL==24]
x[, x$VAL=="24"]
x[, x$"VAL"=="24"]
x$val
x$VAL
x[, x$VAL="24"]
x[, x$VAL == 11]
Y
x[, 1]
x[x$VAL == 24, ]
x[x$VAL == 24, VAL]
x[x$VAL == 24, "VAL"]
x[x$VAL == 24, "VAL", na.rm = T]
x[x$VAL == 24, "VAL", rm.na = T]
x[x$VAL == 24, "VAL", na.rm = TRE]
x[x$VAL == 24, "VAL", na.rm = TRUE]
length(x[x$VAL == 24, "VAL"])
length(x[x$VAL == 24, "VAL"], na.rm = TRUE)
length(complete.cases(x[x$VAL == 24, "VAL"]))
x[x$VAL == 24, "VAL"]
val24 <- x[x$VAL == 24, "VAL"]
length[val24[!is.na(val24)]]
length(val24[!is.na(val24)])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download(fileUrl, destfile="./data/gov_NGAP.xlsx", method="curl")
download.file(fileUrl, destfile="./data/gov_NGAP.xlsx", method="curl")
download.file(fileUrl, destfile="./data/gov_NGAP.xlsx")
colIndex <- 7:15
rowIndex <- 18:23
library(xlsx)
govNGAPData <- read.xlsx("./data/gov_NGAP.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
govNGAPData <- read.xlsx("./data/gov_NGAP.xlsx", sheetIndex = 1)
download.file(fileUrl, destfile="./data/gov_NGAP.xlsx")
download.file(fileUrl, destfile="./data/gov_NGAP.xlsx")
download.file(fileUrl, destfile="./data/gov_NGAP.xlsx", method = "curl")
govNGAPData <- read.xlsx("./data/getdata-data-DATA.gov_NGAP.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
library(xlsx)
govNGAPData <- read.xlsx("./data/getdata-data-DATA.gov_NGAP.xlsx", sheetIndex = 1, colIndex = colIndex, rowIndex = rowIndex)
dat <- govNGAPData
sum(dat$Zip*dat$Ext,na.rm=T)
library(XML)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
library(RMySQL)
ucscDb <- dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDb, "show datablses;")
result <- dbGetQuery(ucscDb, "show datablses;");
result <- dbGetQuery(ucscDb, "show databases;");
dbDisconnect(ucscDb)
result
hg19 <- dbConnect(MySQL(), user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query);
quantile(affyMis$misMatches)
affyMissSmall <- fetch(query, n=10);dbClearResult(query);
dim(affyMissSmall)
dbDisconnect(hg19)
library(rhdf5)
created = h5createFile("example.h5")
created = h5createFile("example1.h5")
created
created = h5createGroup("example1.h5","foo")
created = h5createGroup("example1.h5","baa")
created = h5createGroup("example1.h5","foo/foobaa")
h5ls("example1.h5")
A = matrix(1:10,nr=5,nc=2)
h5write(A, "example1.h5", "foo/A")
B = array(seq(0.1,2.0,by=0.1),dim=c(5,2,2))
attr(B,"scale") <- "liter"
h5write(B, "example1.h5", "foo/foobaa/B")
h5ls("example1.h5")
h5write(A, "example1.h5", "baa")
readA = h5read("example1.h5", "foo/A")
readA
con = url("https://www.baidu.com/")
htmlCode = readLines(con)
close(con)
htmlCode
library(XML)
url <- "https://www.baidu.com/"
html <- htmlTreeParse(url, useInternalNodes = T)
library(httr)
html2 = GET(url)
content2 = content(html2,as="text")
content1
content2
parsedHtem = htmlParse(conten2, asText=T)
parsedHtem = htmlParse(content2, asText=T)
parsedHtml = htmlParse(content2, asText=T)
xpathSApply(parsedHtml, "//title", xmlValue)
library(httr)
oauth_endpoints("github")
myapp
myapp <- oauth_app("e59d43c0782f651c8d8e", "f1cb9ed0cc2a266ec5fff9053a41edc53fb18f2e")
myapp <- oauth_app("e59d43c0782f651c8d8e", "9f7c7f5d3d439c158511755a6dd780ccc4fb09e2")
myapp <- oauth_app("mygithubapp", "e59d43c0782f651c8d8e")
myapp <- oauth_app("github", "e59d43c0782f651c8d8e")
myapp <- oauth_app("github", "936a417636f85b50aa94")
oauth_endpoints("github")
myapp <- oauth_app("github")
myapp <- oauth_app("github", "f36ed4b91cfd3638445d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
gtoken <- config(token = github_token)
req <- with_config(gtoken, GET("https://api.github.com/rate_limit"))
stop_for_status(req)
content(req)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", "f36ed4b91cfd3638445d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
content(req)
myapp <- oauth_app("github", "f36ed4b91cfd3638445d", "cd6e3eb570681bbcaab0785f62ff90c235482b5d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
content(req)
myapp <- oauth_app("github", "f36ed4b91cfd3638445d", "cd6e3eb570681bbcaab0785f62ff90c235482b5d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
content(req)
myapp <- oauth_app("github", "f36ed4b91cfd3638445d", "cd6e3eb570681bbcaab0785f62ff90c235482b5d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/rate_limit", gtoken)
content(req)
myapp <- oauth_app("github", "f36ed4b91cfd3638445d", "cd6e3eb570681bbcaab0785f62ff90c235482b5d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
content(req)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html ")
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlConde = readLines(con)
htmlConde = readLines(con)
head(htmlCode)
apply(htmlCode, nchar
)
class(htmlCode)
fgets(htmlCode, nchar)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
head(htmlCode, 10)
head(htmlCode, 11)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlConde = readLines(con)
cloase(con)
close(con)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
connection <- url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode <- readLines(connection)
close(connection)
c(nchar(htmlCode[10]), nchar(htmlCode[20]), nchar(htmlCode[30]), nchar(htmlCode[100]))
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
d <- read.fwf(url, w, header=FALSE, skip=4, col.names=colNames)
d <- d[, grep("^[^filler]", names(d))]
sum(d[, 4])
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
req <- GET("https://api.github.com/users/jtleek/repos", config(token = github_token))
stop_for_status(req)
output <- content(req)
list(output[[4]]$name, output[[4]]$created_at)
X
set.seed(13435)
X <- data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),];X$var2[c(1,3)] = NA
X
sample(1:5)
X[which(X$var2>2),]
X[X$var2>2,]
X[which(X$var2>2),]
sort(X$var1)
sort(X$var1, decreasing = T)
sort(X$var2)
sort(X$var2, na.last = T)
X[order(X$var1),]
X[order(X$var1, X$var3),]
library(plyr)
arrange(X, var1)
arrange(X, desc(var1)
)
X$var4 <- rnorm(5)
arrange(X, var4)
Y <- cbind(X, rnorm(5))
Y
if (!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileUrl, destfile="./data/restaurants.csv",method="curl")
download.file(fileUrl, destfile="./data/restaurants.csv")
restData <- read.csv("./data/restaurants.csv")
head(restData, n=3)
tail(restData,n=3)
summary(restD)
summary(restData)
str(restData)
quantile(restData$councilDistrict, na.rm=T)
quantile(restData$councilDistrict, probs=c(0.5,0.75,0.9))
table(restData$zipCode,useNA = "ifany")
table(restData$zipCode,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
table(restData$zipCode %in% c("21212"))
restData[restData$zipCode %in% c("21212", "21213")]
restData[restData$zipCode %in% c("21212", "21213"),]
data(UCBAdmissions)
DF == as.data.frame(UCBAdmissions)
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit, data=DF)
xt
head(DF)
df
DF
xt
warpbreaks$replicate <- rep(1:9, len=54)
xt = xtabs(breaks ~., data=warpbreaks)
xt
ftable(xt)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
s1 <- seq(1,10,by=2)
s1
s2 <- seq(1,10,length=3)
s
s2
x <- c(1,3,8,25,100)
seq(along = x)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode < 0, T, F)
table(restData$zipWrong)
table(restData$zipWrong, restDa)
table(restData$zipWrong, restData$zipCode<0)
restData$zipGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
table(restData$zipGroups, restData$zipc)
table(restData$zipGroups, restData$zipcode)
table(restData$zipGroups, restData$zipcode)
table(restData$zipGroups,restData$zipcode)
table(restData$zipGroups)
table(restData$zipGroups, $restData$zipCode)
table(restData$zipGroups, restData$zipCode)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
yesno <- sample(c("yes","no"), size=10,replace=T)
yesno
yesnofac = factor(yesno, levels=c("yes","no"))
relevel(yesnofac,ref="yes")
library(plyr)
restData2 = mutate(restData, zipGroups = cut2(zipCode, g=4))
table(restData2$zipGroups)
library(reshapes2)
install.packages("reshape2")
install.packages("reshape2")
library(reshape2)
head(mtcar)
head(mtcars)
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
carMelt
head(carMelt, n=3)
tail(carMelt, n=3)
clyData <- dcast(carMelt, cyl ~ variable)
cylData <- dcast(carMelt, cyl ~ variable)
cylData
cylData <- dcast(carMelt, cyl ~ variable, mean)
cylData
head(InsectSprays)
tapply(InsectSprays$count,InsectSprays$spray,sum)
tapply(InsectSprays$count,sum)
tapply(InsectSprays$count,InsectSprays$spray,sum)
tapply(InsectSprays$count,InsectSprays$spray)
tapply(InsectSprays$count,InsectSprays$spray, mean)
spIns = split(InsectSprays$count,InsectSprays$spray)
spINs
spIns
sprCount = lapply(spIns, sum)
sprCunt
sprCount
unlist(sprC)
unlist(sprCount)
sapply(spIns, sum)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
library(plyr)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
ddply(InsectSprays,.(spray),summarize,sum=count)
ddply(InsectSprays,.(spray),summarize,sum=mean(count))
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
spraysSums <- ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum))
spraysSums
install.packages("dplyr")
library(dplyr)
chicago <- readRDS("chicago.rds")
chicago <- readRDS("chicago.rds")
fileUrl1 = "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 = "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl1,destfile="./data/reviews.csv",method="curl")
download.file(fileUrl1,destfile="./data/reviews.csv")
download.file(fileUrl1,destfile="./data/reviews.csv")
download.file(fileUrl1,destfile="./data/reviews.csv")
download.file(fileUrl1,destfile="./data/reviews.csv")
x <- read.csv(./data/2006_microdata_survey_about_housing_Idaho.csv"")
x <- read.csv("./data/2006_microdata_survey_about_housing_Idaho.csv")
names(x)
x$AGS = 6
head(x)
head(x$AG)
head(x$AGS)
x$AGS == 6
x[which(x$ACR==3 & x$AGS==6),]
head(x[which(x$ACR==3 & x$AGS==6),])
head(x[which(x$ACR==3 & x$AGS==6),1])
head(x[which(x$ACR==3 & x$AGS==6), 2])
head(x[which(x$ACR==3 & x$AGS==6), 1:2])
head(x[which(x$ACR==3 & x$AGS==6), c("ACR","AGS")])
x <- read.csv("./data/getdata-data-ss06hid.csv")
head(x[which(x$ACR==3 & x$AGS==6), c("ACR","AGS")])
library(jpeg)
install.packages("jpeg")
library(jpeg)
readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = T)
readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = T)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
readJPEG(url, native = T)
z <- tempfile()
download.file(url,z,mode="wb")
download.file(url,z,mode="wb")
download.file(url,z,mode="wb")
file.remove(z)
z <- tempfile()
download.file(url,z,mode="wb")
pic <- readJPEG(z)
file.remove(z)
class(pic)
head(pic)
tail(pic)
array
pic
dim(pic)
head(pic)
f <- file.path(getwd(),"jeff.jpg")
download.file(url,f,mode="wb")
download.file(url,f,mode="wb")
pic <- readJPEG(f, native = T)
head(pic)
quantile(pic, probs=c(0.3,0.8))
url1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
url2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url1, "./data/GDP.csv");download.file(url2,"./data/edstats_country.csv")
d1 <- read.csv(./data/GDP.csv"")
d1 <- read.csv("./data/GDP.csv");d2 <- read.csv("./data/edstats_country.csv")
head(d1)
head(d2)
d1 <- read.csv("./data/GDP.csv");d2 <- read.csv("./data/edstats_country.csv")
head(d1)
merge(d1,d2,by.x="CountryCode",by.y="CountryCode",all=T)
mergeData <- merge(d1,d2,by.x="CountryCode",by.y="CountryCode",all=T)
head(mergeData)
d1 <- read.csv("./data/GDP.csv");d2 <- read.csv("./data/edstats_country.csv")
mergeData <- merge(d1,d2,by.x="CountryCode",by.y="CountryCode",all=T)
head(mergeData)
mergeData <- merge(d1,d2,by.x="CountryCode",by.y="CountryCode",all=F)
mergeData
sum(!is.na(unique(dt$Ranking)))
sum(!is.na(unique(mergeData$Ranking)))
mergeData <- merge(d1,d2,by.x="CountryCode",by.y="CountryCode",all=T)
sum(!is.na(unique(mergeData$Ranking)))
mergeData[order(Ranking),decreasing=T),][13]
mergeData[order(Ranking,decreasing=T),][13]
mergeData[order(mergeData$Ranking,decreasing=T),][13]
mergeData[order(mergeData$Ranking,decreasing=T),][13,]
dt[,mean(Ranking, na.rm=T),by=Income.Group]
mergeData[,mean(Ranking, na.rm=T),by=Income.Group]
tapply(mergeData$Ranking, mergeData$Income.Group,mean)
tapply(mergeData$Ranking, mergeData$Income.Group,mean,na.rm = TRUE)
breaks <- quantile(mergeData$Ranking, probs=seq(0,1,0.2),na.rm=T)
mergeData$quantileGDP <- cut(mer)
mergeData$quantileGDP <- cut(mergeData$Ranking,breaks=breaks)
table(mergeData$quantileGDP, mer)
table(mergeData$quantileGDP, mergeData$Income.Group)
quantile(pic, probs=c(0.3,0.8))
